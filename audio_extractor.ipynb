{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlNBTndgn0j083YVyRbUIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnmolManiDubey/Transer/blob/main/audio_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MSf1QCB2h9-"
      },
      "outputs": [],
      "source": [
        "# the program will extract audio from a given video file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy\n",
        "!pip install openai-whisper\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install gtts\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6oacEPo2rRf",
        "outputId": "fb52b0bf-a9de-442b-b453-9a1e30573075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio extraction"
      ],
      "metadata": {
        "id": "GrxnyWSOALfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extract_audio(video_path, output_path):\n",
        "    # Load the video clip\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "\n",
        "    # Extract the audio\n",
        "    audio_clip = video_clip.audio\n",
        "\n",
        "    # Write the audio to a file\n",
        "    audio_clip.write_audiofile(output_path)\n",
        "\n",
        "    # Close the clips\n",
        "    audio_clip.close()\n",
        "    video_clip.close()\n",
        "\n",
        "\n",
        "video_path = \"/content/sample1.mp4\"  # Update with the path to your video file\n",
        "output_path = \"/content/audio.mp3\"  # Update with the desired path for the extracted audio\n",
        "\n",
        "extract_audio(video_path, output_path)\n",
        "\n",
        "print(\"Audio extraction complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5obEuJV2t0k",
        "outputId": "5eb70c2f-aa8f-482e-86b5-0a4bedc54ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio extraction complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text extraction"
      ],
      "metadata": {
        "id": "HEPu-DtpASM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def recognize_speech_whisper(audio_path):\n",
        "    # Load the pre-trained Whisper model\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Transcribe the audio file\n",
        "    result = model.transcribe(audio_path)\n",
        "\n",
        "    # Extract the transcribed text from the result\n",
        "    text = result[\"text\"]\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "audio_path = \"/content/audio.mp3\"\n",
        "transcribed_text = recognize_speech_whisper(audio_path)\n",
        "print(transcribed_text)\n"
      ],
      "metadata": {
        "id": "ik2PMyzR45_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e1eaaa-422d-479d-c2ff-b57245efd01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 104MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So you and I, if we were married, oh no, exactly, okay? If you and I were married, I wouldn't want to give you what you need. That's all I'm talking about, taking care of each other the best you can. What's wrong with taking care of the woman? She takes care of you? We'll have a hard time finding you like that, those days. You think so? I don't know. Lightning could strike.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation"
      ],
      "metadata": {
        "id": "k2kBCKVhAbA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "def translate_text(text, target_language='es'):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(text, dest=target_language)\n",
        "    return translation.text\n",
        "\n",
        "def get_target_language():\n",
        "    print(\"Choose the language you want to translate the text into:\")\n",
        "    print(\"1. Spanish\")\n",
        "    print(\"2. French\")\n",
        "    print(\"3. German\")\n",
        "    choice = input(\"Enter your choice (1/2/3): \")\n",
        "    if choice == '1':\n",
        "        return 'es'\n",
        "    elif choice == '2':\n",
        "        return 'fr'\n",
        "    elif choice == '3':\n",
        "        return 'de'\n",
        "    else:\n",
        "        print(\"Invalid choice. Defaulting to Spanish.\")\n",
        "        return 'es'\n",
        "\n",
        "\n",
        "text_to_translate = input(\"Enter the text to translate: \")\n",
        "target_language = get_target_language()\n",
        "translated_text = translate_text(text_to_translate, target_language)\n",
        "print(\"Translated text:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGh7G6rfAJiQ",
        "outputId": "99775c75-bd26-4da1-f489-6aa9fdba5e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text to translate:  So you and I, if we were married, oh no, exactly, okay? If you and I were married, I wouldn't want to give you what you need. That's all I'm talking about, taking care of each other the best you can. What's wrong with taking care of the woman? She takes care of you? We'll have a hard time finding you like that, those days. You think so? I don't know. Lightning could strike.\n",
            "Choose the language you want to translate the text into:\n",
            "1. Spanish\n",
            "2. French\n",
            "3. German\n",
            "Enter your choice (1/2/3): 2\n",
            "Translated text: Alors toi et moi, si nous étions mariés, oh non, exactement, d'accord?Si vous et moi étions mariés, je ne voudrais pas vous donner ce dont vous avez besoin.C'est tout ce dont je parle, en prenant soin les uns des autres du mieux que vous pouvez.Quel est le problème à prendre soin de la femme?Elle prend soin de vous?Nous aurons du mal à vous trouver comme ça, ces jours-là.Tu penses?Je ne sais pas.La foudre pourrait frapper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translated text to speech"
      ],
      "metadata": {
        "id": "5k6hITF7BDvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "def convert_text_to_audio(text_to_convert, language='en', output_filename='output.mp3'):\n",
        "    tts = gTTS(text=text_to_convert, lang=language, slow=False)\n",
        "    tts.save(output_filename)\n",
        "    return output_filename\n",
        "\n",
        "# Example usage\n",
        "text_to_convert = \"Alors toi et moi, si nous étions mariés, oh non, exactement, d'accord?Si vous et moi étions mariés, je ne voudrais pas vous donner ce dont vous avez besoin.C'est tout ce dont je parle, en prenant soin les uns des autres du mieux que vous pouvez.Quel est le problème à prendre soin de la femme?Elle prend soin de vous?Nous aurons du mal à vous trouver comme ça, ces jours-là.Tu penses?Je ne sais pas.La foudre pourrait frapper.\"  # Replace with the text you want to convert to speech\n",
        "language = 'fr'  # Replace with the desired language code (e.g., 'en' for English, 'fr' for French, etc.)\n",
        "output_filename = '/content/output.mp3'  # Output audio file name\n",
        "\n",
        "audio_file = convert_text_to_audio(text_to_convert, language, output_filename)\n",
        "print(\"Audio file saved as:\", audio_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDpx1XCJBHGv",
        "outputId": "50817fb5-2c2f-46fe-f8b4-594e1f84859a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio file saved as: /content/output.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Generation"
      ],
      "metadata": {
        "id": "qqpsp8O6E5Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AnmolManiDubey/Wav2Lip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAyaRQ3PCtJ3",
        "outputId": "3043ec6c-a6e6-40c0-eae6-4ec05c8cdf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uVu4iYaFBh8",
        "outputId": "87221229-5f41-4ddc-9ede-e105f7b48eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.58.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 4)) (12.5.40)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 7)) (0.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 1)) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "from Wav2Lip.inference import LipSync\n",
        "\n",
        "# Initialize LipSync model\n",
        "lip_sync_model = LipSync()\n",
        "\n",
        "# Define paths and parameters\n",
        "checkpoint_path = \"/content/Wav2Lip/checkpoints/wav2lip_gan.pth\"\n",
        "face_image_path = \"/content/face_image.jpg\"\n",
        "translated_audio_path = \"/content/output.mp3\"\n",
        "\n",
        "# Load input video\n",
        "input_video_path = \"/content/sample1.mp4\"\n",
        "input_video_clip = VideoFileClip(input_video_path)\n",
        "\n",
        "# Initialize Wav2Lip model\n",
        "wav2lip = Wav2Lip(checkpoint_path=checkpoint_path, face=face_image_path, audio=translated_audio_path)\n",
        "\n",
        "# Extract lip movements from audio\n",
        "lip_keyframes = wav2lip.extract_lip_keyframes()\n",
        "\n",
        "# Generate deepfake video\n",
        "output_video_path = \"/content/output_deepfake.mp4\"\n",
        "wav2lip.generate_deepfake(input_video_clip, lip_keyframes, output_video_path)\n",
        "\n",
        "print(\"Deepfake video generated:\", output_video_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Hjo9VjA8FCTz",
        "outputId": "49a7b47f-983a-4730-9333-011d69657c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] --checkpoint_path CHECKPOINT_PATH --face FACE --audio AUDIO\n",
            "                                [--outfile OUTFILE] [--static STATIC] [--fps FPS]\n",
            "                                [--pads PADS [PADS ...]]\n",
            "                                [--face_det_batch_size FACE_DET_BATCH_SIZE]\n",
            "                                [--wav2lip_batch_size WAV2LIP_BATCH_SIZE]\n",
            "                                [--resize_factor RESIZE_FACTOR] [--crop CROP [CROP ...]]\n",
            "                                [--box BOX [BOX ...]] [--rotate] [--nosmooth]\n",
            "colab_kernel_launcher.py: error: the following arguments are required: --checkpoint_path, --face, --audio\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DBog557fFU74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}